{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Richie\n",
      "[nltk_data]     Zhang\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import scipy\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.edge.service import Service\n",
    "from selenium.webdriver.edge.options import Options\n",
    "from webdriver_manager.microsoft import EdgeChromiumDriverManager\n",
    "import undetected_chromedriver as uc\n",
    "import time\n",
    "import nltk\n",
    "nltk.download('punkt')  # Download the Punkt tokenizer for sentence splitting\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richie Zhang\\AppData\\Local\\Temp\\ipykernel_42904\\3882997704.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path)\n"
     ]
    }
   ],
   "source": [
    "# Initialize CrudeBERT tokenizer and model\n",
    "config_path = './crude_bert_config.json' \n",
    "model_path = './crude_bert_model.bin'\n",
    "config = AutoConfig.from_pretrained(config_path)\n",
    "model = AutoModelForSequenceClassification.from_config(config)\n",
    "state_dict = torch.load(model_path)\n",
    "state_dict.pop(\"bert.embeddings.position_ids\", None)\n",
    "model.load_state_dict(state_dict, strict=False) # Using strict=False to ignore non-critical mismatches\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to output sentiment scores using model\n",
    "def predict_sentiment_for_weekly_df(weekly_df, model, tokenizer):\n",
    "    model.eval()\n",
    "    results = []\n",
    "    class_names = [\"negative\", \"neutral\", \"positive\"]\n",
    "\n",
    "    # Iterate through each row in the weekly DataFrame\n",
    "    for _, row in weekly_df.iterrows():\n",
    "        week_date = row['week_date']\n",
    "        press_releases = row['press_releases']\n",
    "        \n",
    "        # If there are press releases for this week, perform sentiment analysis\n",
    "        if pd.notna(press_releases):\n",
    "            combined_text = \" \".join(press_releases)\n",
    "            \n",
    "            # Split the combined_text into individual sentences\n",
    "            sentences = sent_tokenize(combined_text)\n",
    "            \n",
    "            # Store the sentiment scores for each sentence\n",
    "            sentence_scores = []\n",
    "            \n",
    "            for sentence in sentences:\n",
    "\n",
    "                # Tokenize and encode the sentence\n",
    "                inputs = tokenizer(\n",
    "                    sentence, \n",
    "                    return_tensors=\"pt\", \n",
    "                    padding=True, \n",
    "                    truncation=True, \n",
    "                    max_length=512\n",
    "                )\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    outputs = model(**inputs)\n",
    "                    logits = outputs.logits\n",
    "                    softmax_scores = torch.nn.functional.softmax(logits, dim=-1)\n",
    "                    print(softmax_scores)\n",
    "                    # Calculate sentiment score for this sentence\n",
    "                    negative_score = softmax_scores[0][0].item()\n",
    "                    neutral_score = softmax_scores[0][1].item()\n",
    "                    positive_score = softmax_scores[0][2].item()\n",
    "                    \n",
    "                    # Sentiment score ranges from -1 (negative) to 1 (positive)\n",
    "                    sentiment_score = (-10 * negative_score) + (0 * neutral_score) + (10 * positive_score)\n",
    "                    sentence_scores.append(sentiment_score)\n",
    "                    print(sentiment_score)\n",
    "            # Average the sentiment scores across sentences\n",
    "            avg_sentiment_score = sum(sentence_scores) / len(sentence_scores)\n",
    "            \n",
    "            # Append the weekly data with sentiment result\n",
    "            results.append([week_date, press_releases, avg_sentiment_score])\n",
    "        else:\n",
    "            # If no press releases, keep NaN for sentiment\n",
    "            results.append([week_date, press_releases, np.nan])\n",
    "\n",
    "    # Create a DataFrame with week_date, press_releases, and sentiment columns\n",
    "    sentiment_df = pd.DataFrame(results, columns=[\"week_date\", \"press_releases\", \"sentiment\"])\n",
    "    return sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred on https://www.opec.org/opec_web/en/press_room/7377.htm: Message: no such element: Unable to locate element: {\"method\":\"css selector\",\"selector\":\".headline\"}\n",
      "  (Session info: chrome=130.0.6723.91); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\n",
      "Stacktrace:\n",
      "\tGetHandleVerifier [0x00DE38B3+24035]\n",
      "\t(No symbol) [0x00D6BC44]\n",
      "\t(No symbol) [0x00C4C2D3]\n",
      "\t(No symbol) [0x00C8DC86]\n",
      "\t(No symbol) [0x00C8DECB]\n",
      "\t(No symbol) [0x00CCB9D2]\n",
      "\t(No symbol) [0x00CAFED4]\n",
      "\t(No symbol) [0x00CC953F]\n",
      "\t(No symbol) [0x00CAFC26]\n",
      "\t(No symbol) [0x00C8218C]\n",
      "\t(No symbol) [0x00C8310D]\n",
      "\tGetHandleVerifier [0x010896D3+2800643]\n",
      "\tGetHandleVerifier [0x010E428E+3172286]\n",
      "\tGetHandleVerifier [0x010DCEA2+3142610]\n",
      "\tGetHandleVerifier [0x00E86C60+692624]\n",
      "\t(No symbol) [0x00D74C5D]\n",
      "\t(No symbol) [0x00D71968]\n",
      "\t(No symbol) [0x00D71B00]\n",
      "\t(No symbol) [0x00D63FB0]\n",
      "\tBaseThreadInitThunk [0x76D8FA29+25]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x76FD75F4+228]\n",
      "\tRtlGetAppContainerNamedObjectPath [0x76FD75C4+180]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "options = uc.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# 1 page for each year\n",
    "main_pages = [\n",
    "    \"https://www.opec.org/opec_web/en/6287.htm\",\n",
    "    \"https://www.opec.org/opec_web/en/6762.htm\",\n",
    "    \"https://www.opec.org/opec_web/en/7093.htm\",\n",
    "    \"https://www.opec.org/opec_web/en/7278.htm\",\n",
    "]\n",
    "\n",
    "\n",
    "all_urls = []\n",
    "\n",
    "# Iterate through each page and collect article links for each press release\n",
    "for main_page in main_pages:\n",
    "    driver.get(main_page)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    # Locate all article links on the main page and store their URLs\n",
    "    article_links = driver.find_elements(By.CSS_SELECTOR, \"div.article h3 a\")\n",
    "    all_urls.extend([link.get_attribute(\"href\") for link in article_links])\n",
    "\n",
    "\n",
    "all_articles = []\n",
    "\n",
    "# Loop through each article URL, open the page, extract content, and move to the next\n",
    "for url in all_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)  \n",
    "\n",
    "    try:\n",
    "        # Extract headline\n",
    "        headline = driver.find_element(By.CLASS_NAME, \"headline\").text\n",
    "\n",
    "        # Extract slim text\n",
    "        slim_texts = driver.find_elements(By.CLASS_NAME, \"slim\")\n",
    "        slim_content = \" \".join([slim.text for slim in slim_texts])\n",
    "\n",
    "        # Extract date (third line in the p.date element)\n",
    "        date_element = driver.find_element(By.CLASS_NAME, \"date\").text.splitlines()\n",
    "        date = date_element[2] if len(date_element) > 2 else \"Date not found\"\n",
    "\n",
    "        # Append each article's details as a dictionary\n",
    "        all_articles.append({\n",
    "            \"date\": date,\n",
    "            \"text\": f\"{headline}\\n{slim_content}\"\n",
    "        })\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred on {url}: {e}\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(all_articles)  \n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.head()\n",
    "df.to_csv(\"opec.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Richie Zhang\\AppData\\Local\\Temp\\ipykernel_42904\\3448391220.py:22: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '13th OPEC and non-OPEC Ministerial Meeting concludes\n",
      "No 02/2021\n",
      "Vienna, Austria\n",
      "05 Jan 2021\n",
      "The 13th OPEC and non-OPEC Ministerial Meeting (ONOMM), held via videoconference, concluded on Tuesday, 5 January 2021.\n",
      "The Meeting, which reconvened following an initial round of discussions on 4 January, reaffirmed the continued commitment of the participating countries in the Declaration of Cooperation (DoC) to a stable market in the mutual interest of producing nations; the efficient, economic and secure supply to consumers; and a fair return on invested capital.\n",
      "In addition, the Meeting recalled the decision taken by all DoC participating countries at the 10th (Extraordinary) ONOMM on 12 April 2020 to adjust downwards overall crude oil production, the unanimous decisions taken at the 11th ONOMM on 6 June 2020, and the outcomes of the 12th ONOMM on 3 December 2020.\n",
      "The Meeting highlighted the unprecedented events of 2020 and shocking impact of the COVID-19 pandemic on the world economy and markets, and commended the DoC participating countries for undertaking the largest and longest crude oil production adjustments in history in response to the exceptional challenges and market conditions caused by the pandemic.\n",
      "It pointed out that rising infections, the return of stricter lockdown measures and growing uncertainties have resulted in a more fragile economic recovery that is expected to carry over into 2021. The Meeting recognized that market sentiment has been buoyed recently by vaccine programmes and improved asset markets, but underscored the need for caution due to prevailing weak demand and poor refining margins, the high stock overhang and other underlying uncertainties.\n",
      "The Meeting acknowledged the need to gradually return 2 mb/d to the market, with the pace being determined according to market conditions. It reconfirmed the decision made at the 12th ONOMM to increase production by 0.5 mb/d starting in January 2021, and adjusting the production reduction from 7.7 mb/d to 7.2 mb/d.\n",
      "The adjustments to the production level for February and March 2021 will be implemented as per the distribution detailed in the attached table. Production adjustments for April and subsequent months will be decided during the monthly ONOMM following the criteria agreed upon in the 12th ONOMM.\n",
      "The Meeting reiterated the need to continue closely monitoring market fundamentals, including non-DoC supply and its impact on the global oil balance and overall market stability.\n",
      "The Meeting noted that high conformity levels have contributed significantly to market rebalancing and stability. Between May and November, participating OPEC and non-OPEC countries contributed to reducing the global supply by approximately 1.9 billion barrels, including voluntary adjustments, and this has been key to the rebalancing of the market.\n",
      "The Meeting drew attention to the exceptional year of 2020 as an outlier that distorts the latest five-year average of OECD commercial oil stock levels. It recommended retaining the 2015-2019 average as a more representative metric, while keeping the latest five-year average for the time being. \n",
      "Furthermore, the Meeting expressed appreciation to participating countries, particularly the United Arab Emirates (UAE) and Angola, which have performed beyond expectation. At the same time, it reiterated the critical importance of adhering to full conformity, and compensating the overproduced volumes in accordance with the statements of the 11th and 12th ONOMM, in order to achieve the objective of market rebalancing and avoid undue delay in the process.\n",
      "It requested all underperforming participating countries to submit their plans for implementation of the required compensation for the overproduced volumes to the OPEC Secretariat by 15 January 2021.\n",
      "The Meeting welcomed HE Dr Mohammad Alfares, Kuwait’s new Minister of Oil and Minister of Electricity and Water, and expressed its appreciation to his predecessor, Dr Khaled A. Al-Fadhel, for his dedication to the DoC process.\n",
      "The Meeting decided to hold the next Joint Ministerial Monitoring Committee (JMMC) Meeting on 3 February 2021, followed by a JMMC Meeting on 3 March 2021 and ONOMM on 4 March 2021. The 13th OPEC and non-OPEC Ministerial Meeting to reconvene on 5 January\n",
      "No 01/2021\n",
      "Vienna, Austria\n",
      "04 Jan 2021\n",
      "The 13th OPEC and non-OPEC Ministerial Meeting has been adjourned until tomorrow, Tuesday, 5 January. The meeting will resume at 15:30 (Vienna time) tomorrow.' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  weekly_df.at[i, 'press_releases'] = weekly_text\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_date</th>\n",
       "      <th>press_releases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>13th OPEC and non-OPEC Ministerial Meeting con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-01-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-01-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-01-31</td>\n",
       "      <td>Kazakhstan conveys its full commitment to comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week_date                                     press_releases\n",
       "0 2021-01-03  13th OPEC and non-OPEC Ministerial Meeting con...\n",
       "1 2021-01-10                                                NaN\n",
       "2 2021-01-17                                                NaN\n",
       "3 2021-01-24                                                NaN\n",
       "4 2021-01-31  Kazakhstan conveys its full commitment to comp..."
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge by dates\n",
    "start_date = pd.to_datetime('2021-01-01')\n",
    "end_date = pd.to_datetime('2024-10-13')  # Set explicit end date to October 13th, 2024\n",
    "\n",
    "weekly_ranges = pd.date_range(start=start_date, end=end_date, freq='W-SUN')  # Use W-SUN to ensure weeks end on Sunday\n",
    "\n",
    "# Create a new DataFrame for the result\n",
    "weekly_df = pd.DataFrame(weekly_ranges, columns=['week_date'])\n",
    "weekly_df['press_releases'] = np.nan\n",
    "\n",
    "# Populate 'press_releases' with concatenated text of articles within each weekly range\n",
    "for i in range(len(weekly_ranges) - 1):\n",
    "    start = weekly_ranges[i]\n",
    "    end = weekly_ranges[i + 1]\n",
    "    \n",
    "    # Filter articles within the current weekly range\n",
    "    articles_in_week = df[(df['date'] >= start) & (df['date'] < end)]\n",
    "    \n",
    "    # Concatenate all texts into a single string or NaN if no articles\n",
    "    if not articles_in_week.empty:\n",
    "        weekly_text = \" \".join(articles_in_week['text'].tolist())\n",
    "        weekly_df.at[i, 'press_releases'] = weekly_text\n",
    "    else:\n",
    "        weekly_df.at[i, 'press_releases'] = np.nan\n",
    "\n",
    "# Display the result\n",
    "weekly_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0156, 0.9829, 0.0014]])\n",
      "-0.014201764948666096\n",
      "tensor([[0.0160, 0.9826, 0.0014]])\n",
      "-0.014568963670171797\n",
      "tensor([[0.0153, 0.9836, 0.0012]])\n",
      "-0.01413851126562804\n",
      "tensor([[0.0169, 0.9817, 0.0013]])\n",
      "-0.01559196412563324\n",
      "tensor([[0.0115, 0.9871, 0.0014]])\n",
      "-0.0101417115656659\n",
      "tensor([[0.0144, 0.9841, 0.0015]])\n",
      "-0.012959280982613564\n",
      "tensor([[0.0243, 0.9733, 0.0024]])\n",
      "-0.02187654795125127\n",
      "tensor([[0.0177, 0.9812, 0.0011]])\n",
      "-0.01661712198983878\n",
      "tensor([[0.0122, 0.9861, 0.0017]])\n",
      "-0.010461708647198975\n",
      "tensor([[0.0121, 0.9858, 0.0021]])\n",
      "-0.009969721781089902\n",
      "tensor([[0.0408, 0.9486, 0.0106]])\n",
      "-0.030191874131560326\n",
      "tensor([[0.0160, 0.9823, 0.0017]])\n",
      "-0.014272570027969778\n",
      "tensor([[0.0159, 0.9829, 0.0012]])\n",
      "-0.014722755178809166\n",
      "tensor([[1.5742e-02, 9.8329e-01, 9.6514e-04]])\n",
      "-0.014777097559999675\n",
      "tensor([[0.0408, 0.9486, 0.0106]])\n",
      "-0.030191874131560326\n",
      "tensor([[0.0203, 0.9749, 0.0048]])\n",
      "-0.015588427428156137\n",
      "tensor([[1.6556e-02, 9.8249e-01, 9.5069e-04]])\n",
      "-0.015605784545186907\n",
      "tensor([[0.0112, 0.9875, 0.0013]])\n",
      "-0.009833176620304585\n",
      "tensor([[0.0144, 0.9843, 0.0012]])\n",
      "-0.013191070989705622\n",
      "tensor([[0.0155, 0.9826, 0.0018]])\n",
      "-0.013695337227545679\n",
      "tensor([[0.0155, 0.9830, 0.0015]])\n",
      "-0.01396809599827975\n",
      "tensor([[0.0175, 0.9807, 0.0018]])\n",
      "-0.015752277220599353\n",
      "tensor([[0.0170, 0.9814, 0.0015]])\n",
      "-0.015500174718908966\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_date</th>\n",
       "      <th>press_releases</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-10-06</td>\n",
       "      <td>Fifth High-Level Meeting of the OPEC-GECF Ener...</td>\n",
       "      <td>-0.015557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-10-13</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   week_date                                     press_releases  sentiment\n",
       "0 2024-10-06  Fifth High-Level Meeting of the OPEC-GECF Ener...  -0.015557\n",
       "1 2024-10-13                                                NaT        NaN"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df = predict_sentiment_for_weekly_df(weekly_df.tail(2), model, tokenizer)\n",
    "\n",
    "sentiment_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
